{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9092aa5e-921f-4134-af31-a801356e83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313964a3-88d8-4dd6-9ec8-e8ec537cf836",
   "metadata": {},
   "source": [
    "# Make functions to extract best model score\n",
    "\n",
    "Because the model scores have different numbers of columns depending on if it is single label or multi label, format two different types of functions. Test them out on an example to make sure they produce similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0195b48-42f0-4d45-9ae8-56f6ea2bfe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_single(modelname, file_path_prefix, k_range):\n",
    "    inner_scores = []\n",
    "    params = ['batch_size','weight_decay','learning_rate','num_epochs','class_weight']\n",
    "    \n",
    "    for k in range(k_range): #Change to 5 if you are using the binary\n",
    "        inner_df = pd.read_csv(f'{file_path_prefix}{k}.csv')\n",
    "        inner_df = inner_df.sort_values('F1',ascending=False).reset_index(drop=True)\n",
    "        inner_scores += inner_df.to_dict('records')\n",
    "    \n",
    "    inner_scores = pd.DataFrame.from_dict(inner_scores).fillna(-1)\n",
    "    best_model = (inner_scores\n",
    "                  .groupby(params).agg({\n",
    "                      'F1':'mean',\n",
    "                      'ROC AUC':'mean',\n",
    "                      'precision':'mean',\n",
    "                      'recall':'mean',\n",
    "                      'accuracy':'mean'\n",
    "                      }).sort_values('F1',ascending=False).reset_index()).to_dict('records')[0]\n",
    "    best_model = pd.DataFrame(best_model,index=[modelname])\n",
    "    del inner_scores, inner_df\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab2527e8-a218-411d-942c-f1508b2e3125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate_mitigation</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.802477</td>\n",
       "      <td>0.938158</td>\n",
       "      <td>0.726099</td>\n",
       "      <td>0.897321</td>\n",
       "      <td>0.879555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    batch_size  weight_decay  learning_rate  num_epochs  \\\n",
       "climate_mitigation          16           0.0        0.00001           2   \n",
       "\n",
       "                    class_weight        F1   ROC AUC  precision    recall  \\\n",
       "climate_mitigation            -1  0.802477  0.938158   0.726099  0.897321   \n",
       "\n",
       "                    accuracy  \n",
       "climate_mitigation  0.879555  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2=get_best_model_single('climate_mitigation',f'/home/dveytia/ORO-map-relevance/outputs/model_selection/climate_mitigation_model_selection_', 3)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185b7857-0623-4c2c-8870-4988d10f7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_multi(modelname, file_path_prefix, k_range): \n",
    "    inner_scores = []\n",
    "    params = ['batch_size','weight_decay','learning_rate','num_epochs','class_weight']\n",
    "    \n",
    "    for k in range(k_range): \n",
    "        inner_df = pd.read_csv(f'{file_path_prefix}{k}.csv')\n",
    "        inner_df = inner_df.sort_values('F1 macro', ascending=False).reset_index(drop=True)\n",
    "        inner_scores += inner_df.to_dict('records')\n",
    "    \n",
    "    inner_scores = pd.DataFrame.from_dict(inner_scores).fillna(-1)\n",
    "    \n",
    "    if 'accuracy macro' not in list(inner_scores.columns): # if there is no accuracy macro column set to dummy value\n",
    "        inner_scores['accuracy macro'] = -999 \n",
    "        \n",
    "    best_model = (inner_scores\n",
    "                  .groupby(params).agg({\n",
    "                      'F1 macro':'mean',\n",
    "                      'ROC AUC macro':'mean',\n",
    "                      'precision macro':'mean',\n",
    "                      'recall macro':'mean',\n",
    "                      'accuracy macro':'mean'\n",
    "                      }).sort_values('F1 macro',ascending=False).reset_index()).to_dict('records')[0]\n",
    "    \n",
    "    best_model = pd.DataFrame(best_model,index=[modelname])\n",
    "    best_model.rename(columns={'F1 macro': 'F1', 'ROC AUC macro': 'ROC AUC', 'precision macro':'precision', 'recall macro':'recall', 'accuracy macro':'accuracy'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    ## Get label information\n",
    "    allLabels = [x for x in inner_scores.columns if 'F1' in x] \n",
    "    allLabels.remove('F1 macro')\n",
    "    allLabels.remove('F1 micro')\n",
    "    allLabels.remove('F1 weighted')\n",
    "    allLabels.remove('F1 samples')\n",
    "    allLabels = [s.replace('F1 - ', '') for s in allLabels]\n",
    "    \n",
    "    best_model['label_names'] = \"temp\"\n",
    "    best_model.at[modelname,'label_names'] = [s.replace(modelname + '.','') for s in allLabels]\n",
    "    \n",
    "    \n",
    "    ## Get label F1s\n",
    "    labelScores = []\n",
    "    for label in allLabels:\n",
    "        best_model_temp = (inner_scores\n",
    "                  .groupby(params).agg({\n",
    "                      'F1'+' - ' + label:'mean'\n",
    "                      }).sort_values('F1'+' - ' + label,ascending=False).reset_index()).to_dict('records')[0]\n",
    "        best_model_temp = pd.DataFrame(best_model_temp, index=[modelname])\n",
    "        labelScores.append(best_model_temp['F1 - '+label])\n",
    "        \n",
    "    best_model['label_F1s'] = \"temp\"\n",
    "    best_model.at[modelname,'label_F1s'] = [ '%.2f' % elem for elem in labelScores]\n",
    "    \n",
    "    \n",
    "    del inner_scores, inner_df\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0410c4f-92a4-4c53-80b5-726585059b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>label_names</th>\n",
       "      <th>label_F1s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adapt_to_threat</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 2.116788321167883, 1: 12.774193548387096, ...</td>\n",
       "      <td>0.470982</td>\n",
       "      <td>0.835704</td>\n",
       "      <td>0.540875</td>\n",
       "      <td>0.494483</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>[Human, Natural, Both]</td>\n",
       "      <td>[0.79, 0.46, 0.34]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 batch_size  weight_decay  learning_rate  num_epochs  \\\n",
       "adapt_to_threat          32           0.0        0.00005           4   \n",
       "\n",
       "                                                      class_weight        F1  \\\n",
       "adapt_to_threat  {0: 2.116788321167883, 1: 12.774193548387096, ...  0.470982   \n",
       "\n",
       "                  ROC AUC  precision    recall  accuracy  \\\n",
       "adapt_to_threat  0.835704   0.540875  0.494483    -999.0   \n",
       "\n",
       "                            label_names           label_F1s  \n",
       "adapt_to_threat  [Human, Natural, Both]  [0.79, 0.46, 0.34]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1=get_best_model_multi('adapt_to_threat',f'/home/dveytia/ORO-map-relevance/outputs/model_selection/adapt_to_threat_model_selection_', 3)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "671cddcb-43df-4344-bdb3-3236892759a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>label_names</th>\n",
       "      <th>label_F1s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate_mitigation</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.802477</td>\n",
       "      <td>0.938158</td>\n",
       "      <td>0.726099</td>\n",
       "      <td>0.897321</td>\n",
       "      <td>0.879555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapt_to_threat</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 2.116788321167883, 1: 12.774193548387096, ...</td>\n",
       "      <td>0.470982</td>\n",
       "      <td>0.835704</td>\n",
       "      <td>0.540875</td>\n",
       "      <td>0.494483</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>[Human, Natural, Both]</td>\n",
       "      <td>[0.79, 0.46, 0.34]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    batch_size  weight_decay  learning_rate  num_epochs  \\\n",
       "climate_mitigation          16           0.0        0.00001           2   \n",
       "adapt_to_threat             32           0.0        0.00005           4   \n",
       "\n",
       "                                                         class_weight  \\\n",
       "climate_mitigation                                                 -1   \n",
       "adapt_to_threat     {0: 2.116788321167883, 1: 12.774193548387096, ...   \n",
       "\n",
       "                          F1   ROC AUC  precision    recall    accuracy  \\\n",
       "climate_mitigation  0.802477  0.938158   0.726099  0.897321    0.879555   \n",
       "adapt_to_threat     0.470982  0.835704   0.540875  0.494483 -999.000000   \n",
       "\n",
       "                               label_names           label_F1s  \n",
       "climate_mitigation                     NaN                 NaN  \n",
       "adapt_to_threat     [Human, Natural, Both]  [0.79, 0.46, 0.34]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([test2, test1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0084fdd-e63e-421f-b904-253de5641b92",
   "metadata": {},
   "source": [
    "# Get all model scores for all single label models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052aef73-7fd9-4747-a42a-b093dcfcec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climate_mitigation\n",
      "Forecast\n",
      "impact_ncp.Any\n",
      "blue_carbon\n",
      "<bound method NDFrame.head of                     batch_size  weight_decay  learning_rate  num_epochs  \\\n",
      "climate_mitigation          16           0.0        0.00001           2   \n",
      "Forecast                    32           0.0        0.00005           4   \n",
      "impact_ncp.Any              16           0.0        0.00001           4   \n",
      "blue_carbon                 16           0.0        0.00005           4   \n",
      "\n",
      "                                    class_weight        F1   ROC AUC  \\\n",
      "climate_mitigation                            -1  0.802477  0.938158   \n",
      "Forecast            {0: 1, 1: 7.714285714285714}  0.559951  0.849199   \n",
      "impact_ncp.Any                                -1  0.464714  0.783744   \n",
      "blue_carbon                                   -1  0.894561  0.988171   \n",
      "\n",
      "                    precision    recall  accuracy  \n",
      "climate_mitigation   0.726099  0.897321  0.879555  \n",
      "Forecast             0.466964  0.730504  0.863921  \n",
      "impact_ncp.Any       0.555556  0.414372  0.865173  \n",
      "blue_carbon          0.966667  0.834936  0.980747  >\n"
     ]
    }
   ],
   "source": [
    "# create a list of all the single label models to loop through\n",
    "singleModels = ['climate_mitigation','Forecast','impact_ncp.Any','blue_carbon'] \n",
    "\n",
    "for model  in singleModels:\n",
    "    print(model)\n",
    "    temp = get_best_model_single(model,f'/home/dveytia/ORO-map-relevance/outputs/model_selection/{model}_model_selection_', 3)\n",
    "    if model == singleModels[0]:\n",
    "        singleModelScores = temp\n",
    "    else:\n",
    "        singleModelScores = pd.concat([singleModelScores, temp])\n",
    "\n",
    "print(singleModelScores.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d5453-18e3-42bf-aede-2ce5a38df3a1",
   "metadata": {},
   "source": [
    "# Get model scores for all multi label models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe418a49-f623-4734-85f8-d968656a8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_type\n",
      "adapt_to_threat\n",
      "adapt_to_threat_simplified\n",
      "adapt_to_threat_simplified2\n",
      "climate_threat\n",
      "ecosystem_type\n",
      "ecosystem_type_simplified\n",
      "impact_ncp_nested\n",
      "m_co2_ocean_storage\n",
      "m_co2_removal\n",
      "marine_system\n",
      "method_type\n",
      "method_type_nested\n",
      "oro_development_stage\n",
      "oro_development_stage_mitigation\n",
      "oro_development_stage_nature\n",
      "oro_development_stage_societal\n",
      "scientific_discipline\n",
      "<bound method NDFrame.head of                                   batch_size  weight_decay  learning_rate  \\\n",
      "data_type                                 32           0.0        0.00001   \n",
      "adapt_to_threat                           32           0.0        0.00005   \n",
      "adapt_to_threat_simplified                16           0.0        0.00005   \n",
      "adapt_to_threat_simplified2               32           0.0        0.00005   \n",
      "climate_threat                            16           0.0        0.00005   \n",
      "ecosystem_type                            16           0.0        0.00005   \n",
      "ecosystem_type_simplified                 16           0.0        0.00005   \n",
      "impact_ncp_nested                         16           0.0        0.00005   \n",
      "m_co2_ocean_storage                       16           0.0        0.00005   \n",
      "m_co2_removal                             16           0.0        0.00005   \n",
      "marine_system                             32           0.0        0.00005   \n",
      "method_type                               16           0.0        0.00005   \n",
      "method_type_nested                        16           0.0        0.00005   \n",
      "oro_development_stage                     16           0.0        0.00005   \n",
      "oro_development_stage_mitigation          32           0.0        0.00005   \n",
      "oro_development_stage_nature              16           0.0        0.00005   \n",
      "oro_development_stage_societal            16           0.0        0.00005   \n",
      "scientific_discipline                     16           0.0        0.00005   \n",
      "\n",
      "                                  num_epochs  \\\n",
      "data_type                                  4   \n",
      "adapt_to_threat                            4   \n",
      "adapt_to_threat_simplified                 3   \n",
      "adapt_to_threat_simplified2                4   \n",
      "climate_threat                             4   \n",
      "ecosystem_type                             4   \n",
      "ecosystem_type_simplified                  3   \n",
      "impact_ncp_nested                          4   \n",
      "m_co2_ocean_storage                        4   \n",
      "m_co2_removal                              4   \n",
      "marine_system                              4   \n",
      "method_type                                4   \n",
      "method_type_nested                         4   \n",
      "oro_development_stage                      4   \n",
      "oro_development_stage_mitigation           4   \n",
      "oro_development_stage_nature               4   \n",
      "oro_development_stage_societal             4   \n",
      "scientific_discipline                      4   \n",
      "\n",
      "                                                                       class_weight  \\\n",
      "data_type                                                                        -1   \n",
      "adapt_to_threat                   {0: 2.116788321167883, 1: 12.774193548387096, ...   \n",
      "adapt_to_threat_simplified                                                       -1   \n",
      "adapt_to_threat_simplified2                                                      -1   \n",
      "climate_threat                                                                   -1   \n",
      "ecosystem_type                    {0: 18.40909090909091, 1: 11.93939393939394, 2...   \n",
      "ecosystem_type_simplified                                                        -1   \n",
      "impact_ncp_nested                                                                -1   \n",
      "m_co2_ocean_storage                                                              -1   \n",
      "m_co2_removal                                                                    -1   \n",
      "marine_system                     {0: 1.7548387096774194, 1: 1.103448275862069, ...   \n",
      "method_type                                                                      -1   \n",
      "method_type_nested                                                               -1   \n",
      "oro_development_stage                                                            -1   \n",
      "oro_development_stage_mitigation                                                 -1   \n",
      "oro_development_stage_nature                                                     -1   \n",
      "oro_development_stage_societal                                                   -1   \n",
      "scientific_discipline                                                            -1   \n",
      "\n",
      "                                        F1   ROC AUC  precision    recall  \\\n",
      "data_type                         0.833349  0.916920   0.821708  0.845885   \n",
      "adapt_to_threat                   0.470982  0.835704   0.540875  0.494483   \n",
      "adapt_to_threat_simplified        0.638819  0.880257   0.601803  0.689973   \n",
      "adapt_to_threat_simplified2       0.717544  0.882999   0.812196  0.675394   \n",
      "climate_threat                    0.542341  0.280862   0.526552  0.596901   \n",
      "ecosystem_type                    0.583865  0.940899   0.611420  0.641581   \n",
      "ecosystem_type_simplified         0.909893  0.986256   0.917379  0.915038   \n",
      "impact_ncp_nested                 0.566783  0.764054   0.525594  0.621083   \n",
      "m_co2_ocean_storage               0.582642  0.968975   0.640358  0.568536   \n",
      "m_co2_removal                     0.259712 -1.000000   0.254980  0.300481   \n",
      "marine_system                     0.704495  0.896709   0.709628  0.723308   \n",
      "method_type                       0.338804  0.828860   0.499967  0.295044   \n",
      "method_type_nested                0.408233  0.862742   0.526500  0.367139   \n",
      "oro_development_stage             0.532326  0.726117   0.594891  0.525998   \n",
      "oro_development_stage_mitigation  0.322649  0.631165   0.377722  0.309094   \n",
      "oro_development_stage_nature      0.286101  0.639222   0.348765  0.330137   \n",
      "oro_development_stage_societal    0.364499  0.651451   0.477319  0.378766   \n",
      "scientific_discipline             0.424032  0.851336   0.454270  0.438301   \n",
      "\n",
      "                                  accuracy  \\\n",
      "data_type                           -999.0   \n",
      "adapt_to_threat                     -999.0   \n",
      "adapt_to_threat_simplified          -999.0   \n",
      "adapt_to_threat_simplified2         -999.0   \n",
      "climate_threat                      -999.0   \n",
      "ecosystem_type                      -999.0   \n",
      "ecosystem_type_simplified           -999.0   \n",
      "impact_ncp_nested                   -999.0   \n",
      "m_co2_ocean_storage                 -999.0   \n",
      "m_co2_removal                       -999.0   \n",
      "marine_system                       -999.0   \n",
      "method_type                         -999.0   \n",
      "method_type_nested                  -999.0   \n",
      "oro_development_stage               -999.0   \n",
      "oro_development_stage_mitigation    -999.0   \n",
      "oro_development_stage_nature        -999.0   \n",
      "oro_development_stage_societal      -999.0   \n",
      "scientific_discipline               -999.0   \n",
      "\n",
      "                                                                        label_names  \\\n",
      "data_type                                                      [Primary, Secondary]   \n",
      "adapt_to_threat                                              [Human, Natural, Both]   \n",
      "adapt_to_threat_simplified        [adapt_to_threat.Human, adapt_to_threat.Natura...   \n",
      "adapt_to_threat_simplified2        [adapt_to_threat.Human, adapt_to_threat.Natural]   \n",
      "climate_threat                    [Temperature, Acidification, SLR, Extreme_weat...   \n",
      "ecosystem_type                    [Salt_marsh, Mangrove, Coral_reef, Macroalgae,...   \n",
      "ecosystem_type_simplified         [ecosystem_type.Mangrove, ecosystem_type.Coral...   \n",
      "impact_ncp_nested                 [impact_ncp.Regulating, impact_ncp.Material, i...   \n",
      "m_co2_ocean_storage                            [Inorganic, Organic, Deep_sediments]   \n",
      "m_co2_removal                     [Bioenergy, Openocean_PP, Macroalgae_kelp_cult...   \n",
      "marine_system                                     [land, coastal ocean, open-ocean]   \n",
      "method_type                       [Experimental_exsitu, Experimental_insitu, Exp...   \n",
      "method_type_nested                [method_type.Experimental_exsitu, method_type....   \n",
      "oro_development_stage             [Design__observeconceptpreliminary_testingside...   \n",
      "oro_development_stage_mitigation  [oro_development_stage.Design__observeconceptp...   \n",
      "oro_development_stage_nature      [oro_development_stage.Design__observeconceptp...   \n",
      "oro_development_stage_societal    [oro_development_stage.Design__observeconceptp...   \n",
      "scientific_discipline             [Chemistry, Biogeochemistry, Biology, Economic...   \n",
      "\n",
      "                                                                          label_F1s  \n",
      "data_type                                                              [0.95, 0.72]  \n",
      "adapt_to_threat                                                  [0.79, 0.46, 0.34]  \n",
      "adapt_to_threat_simplified                                       [0.86, 0.63, 0.43]  \n",
      "adapt_to_threat_simplified2                                            [0.85, 0.60]  \n",
      "climate_threat                                 [0.63, 0.47, 0.81, 0.70, 0.67, 0.00]  \n",
      "ecosystem_type                                 [0.38, 0.94, 0.86, 0.58, 0.83, 0.31]  \n",
      "ecosystem_type_simplified                                        [0.94, 0.88, 0.95]  \n",
      "impact_ncp_nested                                                [0.82, 0.88, 0.00]  \n",
      "m_co2_ocean_storage                                              [0.55, 0.80, 0.45]  \n",
      "m_co2_removal                                  [0.67, 0.33, 0.22, 0.33, 0.27, 0.72]  \n",
      "marine_system                                                    [0.86, 0.78, 0.52]  \n",
      "method_type                              [0.45, 0.07, 0.00, 0.21, 0.43, 0.70, 0.61]  \n",
      "method_type_nested                       [0.55, 0.21, 0.29, 0.42, 0.47, 0.79, 0.70]  \n",
      "oro_development_stage                                            [0.69, 0.43, 0.55]  \n",
      "oro_development_stage_mitigation                                 [0.79, 0.41, 0.31]  \n",
      "oro_development_stage_nature                                     [0.59, 0.25, 0.27]  \n",
      "oro_development_stage_societal                                   [0.35, 0.32, 0.68]  \n",
      "scientific_discipline             [0.72, 0.65, 0.72, 0.17, 0.75, 0.00, 0.37, 0.0...  >\n"
     ]
    }
   ],
   "source": [
    "# create a list of all the multi label models to loop through\n",
    "multiModels = ['data_type','adapt_to_threat','adapt_to_threat_simplified','adapt_to_threat_simplified2', \n",
    "               'climate_threat', 'ecosystem_type','ecosystem_type_simplified',\n",
    "               'impact_ncp_nested',\n",
    "              'm_co2_ocean_storage', 'm_co2_removal',\n",
    "               'marine_system', 'method_type', 'method_type_nested','oro_development_stage',\n",
    "               'oro_development_stage_mitigation','oro_development_stage_nature', 'oro_development_stage_societal',\n",
    "              'scientific_discipline'] # add data\n",
    "\n",
    "for model  in multiModels:\n",
    "    print(model)\n",
    "    temp = get_best_model_multi(model,f'/home/dveytia/ORO-map-relevance/outputs/model_selection/{model}_model_selection_', 3)\n",
    "    if model == multiModels[0]:\n",
    "        multiModelScores = temp\n",
    "    else:\n",
    "        multiModelScores = pd.concat([multiModelScores, temp])\n",
    "\n",
    "print(multiModelScores.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cbfde-75a0-4f81-b10a-10e821fe7d5a",
   "metadata": {},
   "source": [
    "# Join and write all model scores to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9d75468-84f5-4e4c-9888-7b859951b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_all=pd.concat([singleModelScores, multiModelScores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5774431-0224-4676-a87d-bf3e8b98a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_all.to_csv(f'/home/dveytia/ORO-map-relevance/outputs/summary_model_scores.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417318b6-078d-4f16-8049-8a41f1147e4e",
   "metadata": {},
   "source": [
    "# Calcualte the scores for each label (for multi-label models)\n",
    "\n",
    "In the above functions, for a multi label model only the macro scores are reported. If a dataframe is desired that includes the scores for every label, use the following (note that code is not complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d43317a-3a82-486b-9258-745e2fa583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_labels(modelname, file_path_prefix, k_range): \n",
    "    inner_scores = []\n",
    "    params = ['batch_size','weight_decay','learning_rate','num_epochs','class_weight']\n",
    "    \n",
    "    for k in range(k_range): \n",
    "        inner_df = pd.read_csv(f'{file_path_prefix}{k}.csv')\n",
    "        inner_df = inner_df.sort_values('F1 macro', ascending=False).reset_index(drop=True)\n",
    "        inner_scores += inner_df.to_dict('records')\n",
    "    \n",
    "    inner_scores = pd.DataFrame.from_dict(inner_scores).fillna(-1)\n",
    "    \n",
    "    if 'accuracy macro' not in list(inner_scores.columns): # if there is no accuracy macro column set to dummy value\n",
    "        inner_scores['accuracy macro'] = -999 \n",
    "    \n",
    "    # Loop across the different labels to get the best scores\n",
    "    \n",
    "    # get the sames of the different labels\n",
    "    allLabels = [x for x in inner_scores.columns if 'F1' in x] \n",
    "    allLabels.remove('F1 macro')\n",
    "    allLabels.remove('F1 micro')\n",
    "    allLabels.remove('F1 weighted')\n",
    "    allLabels.remove('F1 samples')\n",
    "    allLabels = [s.replace('F1 - ', '') for s in allLabels]\n",
    "    \n",
    "    # start loop\n",
    "    for label in allLabels:\n",
    "        \n",
    "        # get the best model\n",
    "        best_model_temp = (inner_scores\n",
    "                  .groupby(params).agg({\n",
    "                      'F1'+' - ' + label:'mean',\n",
    "                      'ROC AUC'+' - ' + label:'mean',\n",
    "                      'precision'+' - ' + label:'mean',\n",
    "                      'recall'+' - ' + label:'mean',\n",
    "                      'accuracy'+' - ' + label:'mean'\n",
    "                      }).sort_values('F1'+' - ' + label,ascending=False).reset_index()).to_dict('records')[0]\n",
    "        best_model_temp = pd.DataFrame(best_model_temp, index=[modelname])\n",
    "\n",
    "        # take label name out of column names so that everything is general \n",
    "        best_model_temp.columns = [s.replace(' - ' + label, '') for s in list(best_model_temp.columns)] \n",
    "\n",
    "        # add a column name saying the label\n",
    "        best_model_temp.insert(0, 'label', label) \n",
    "        \n",
    "        # join all together\n",
    "        if label == allLabels[0]:\n",
    "            labelScores = best_model_temp\n",
    "        else:\n",
    "            labelScores = pd.concat([labelScores, best_model_temp])\n",
    "    del inner_scores, inner_df, allLabels, best_model_temp\n",
    "    return labelScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4622be3a-24f8-4acd-ab13-a54279e86681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_type\n",
      "adapt_to_threat\n",
      "adapt_to_threat_simplified\n",
      "adapt_to_threat_simplified2\n",
      "climate_threat\n",
      "ecosystem_type\n",
      "ecosystem_type_simplified\n",
      "impact_ncp_nested\n",
      "m_co2_ocean_storage\n",
      "m_co2_removal\n",
      "marine_system\n",
      "method_type\n",
      "method_type_nested\n",
      "oro_development_stage\n",
      "oro_development_stage_mitigation\n",
      "oro_development_stage_nature\n",
      "oro_development_stage_societal\n",
      "scientific_discipline\n"
     ]
    }
   ],
   "source": [
    "for model  in multiModels:\n",
    "    print(model)\n",
    "    temp = get_best_model_labels(model,f'/home/dveytia/ORO-map-relevance/outputs/model_selection/{model}_model_selection_', 3)\n",
    "    if model == multiModels[0]:\n",
    "        multiModelLabelScores = temp\n",
    "    else:\n",
    "        multiModelLabelScores = pd.concat([multiModelLabelScores, temp])\n",
    "\n",
    "multiModelLabelScores.to_csv(f'/home/dveytia/ORO-map-relevance/outputs/summary_model_label_scores.csv', index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilBERT_env",
   "language": "python",
   "name": "distilbert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
