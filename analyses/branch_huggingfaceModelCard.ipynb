{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df17587-4fb4-425f-b2bd-15428e25b2d0",
   "metadata": {},
   "source": [
    "# Hugging Face model card for DistilBERT uncased text classification model: ORO branch classification\n",
    "\n",
    "This script will use the model configuration with the hyperparameters determined from 05_Multilabel_1_oro_branch directory, and fit using the whole dataset. This is different than the model predictions obtained from the nested cross validation script which fits models on splits of the data for a distribution of predicitons. This is because a model card can only have one model. So the purpose is just to provide an approximation/example, knowing that the model will likely be overfit compared to the predictions presented in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b545fb-db6a-4e55-adf0-232f32bb7f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dveytia/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-12 15:39:53.844710: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-12 15:39:53.967765: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-12 15:39:54.493757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-12 15:39:54.493809: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-12 15:39:54.493815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-12 15:39:56.337141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-12 15:39:56.928849: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-03-12 15:39:56.929262: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:121] DRIVER VERSION: 11040\n",
      "2024-03-12 15:39:56.929370: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:172] gpu_async_0 CudaMallocAsync initialized on platform: 0 with pool size of: 283967488 this ptr: 0x20660180\n",
      "2024-03-12 15:39:56.929385: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:263] gpu_async_0 GpuCudaMallocAsyncAllocator PoolSize 283967488\n",
      "2024-03-12 15:39:56.929423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 270 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2024-03-12 15:39:56.961365: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 1028 bytes.\n",
      "2024-03-12 15:39:56.961400: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 1028 at 0x302000000\n",
      "2024-03-12 15:39:56.962786: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 1032 bytes.\n",
      "2024-03-12 15:39:56.962802: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 4 at 0x302000600\n",
      "2024-03-12 15:39:56.965252: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 1036 bytes.\n",
      "2024-03-12 15:39:56.965266: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 4 at 0x302000800\n",
      "/opt/miniconda3/envs/distilBERT_env_3.8_modelCard/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load modules\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import pandas as pd\n",
    "#import os\n",
    "#os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "#os.environ[\"TF_CPP_VMODULE\"]=\"gpu_process_state=10,gpu_cudamallocasync_allocator=10\"\n",
    "import tensorflow as tf\n",
    "a = tf.zeros([], tf.float32)\n",
    "import tensorflow_addons as tfa\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38d5e8-1c3a-4ee4-8da4-7d1739b7f3d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the best model parameters determined from the model selection CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f764e79-1ff4-4235-bcfd-b7960d1a42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which model, tokenizer that will be used to fit the model\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d81065-dede-4256-8110-e30a96132f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the parameters from the model selection\n",
    "inner_scores = []\n",
    "params = ['batch_size','weight_decay','learning_rate','num_epochs','class_weight']\n",
    "\n",
    "for k in range(3):\n",
    "    inner_df = pd.read_csv(f'/home/dveytia/ORO-map-relevance/outputs/model_selection/oro_branch_model_selection_{k}.csv')\n",
    "    inner_df = inner_df.sort_values('F1 macro',ascending=False).reset_index(drop=True)\n",
    "    inner_scores += inner_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb49f9df-f28e-439b-99b0-2e5df816f32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 1e-05, 'num_epochs': 3, 'class_weight': -1}\n"
     ]
    }
   ],
   "source": [
    "# From all the folds used for model selection, find the best model\n",
    "inner_scores = pd.DataFrame.from_dict(inner_scores).fillna(-1)\n",
    "inner_scores['F1 - tp'] = inner_scores.loc[:, [col for col in inner_scores.columns if col.startswith('F1 -')]].mean(axis=1) #and any(target in col for target in targets)\n",
    "\n",
    "best_model_params = (inner_scores\n",
    "              .groupby(params)['F1 - tp'] # This is the same as groupig through F1-macro\n",
    "              .mean()\n",
    "              .sort_values(ascending=False)\n",
    "              .reset_index() \n",
    "             ).to_dict('records')[0]\n",
    "\n",
    "del best_model_params['F1 - tp']\n",
    "print(best_model_params)\n",
    "\n",
    "#if best_model_params['class_weight']==-1:\n",
    "#    best_model_params['class_weight']=None\n",
    "#else:\n",
    "#    best_model_params['class_weight'] = ast.literal_eval(best_model_params['class_weight'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d7d4f4-30ea-4685-8718-440dc89c9ca1",
   "metadata": {},
   "source": [
    "## Using the best parameters, fit the model on the full seen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b51ac45d-8e6e-4560-b07d-5dcadcd9b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in and Format the oro_branch coding data \n",
    "\n",
    "## The 'seen' data\n",
    "codedVariablesTxt = '/home/dveytia/ORO-map-relevance/data/seen/all-coding-format-distilBERT-simplifiedMore.txt'\n",
    "screenDecisionsTxt = '/home/dveytia/ORO-map-relevance/data/seen/all-screen-results_screenExcl-codeIncl.txt'\n",
    "\n",
    "df = pd.read_csv(codedVariablesTxt, delimiter='\\t')\n",
    "df = df.rename(columns={'analysis_id':'id'})\n",
    "\n",
    "screendf = pd.read_csv(screenDecisionsTxt, delimiter='\\t')\n",
    "screendf = screendf.query('include_screen==1')\n",
    "screendf = screendf.rename(columns={'include_screen':'relevant','analysis_id':'id'})\n",
    "\n",
    "df = df.merge(screendf[['id', 'sample_screen']], on='id', how='left')\n",
    "\n",
    "def map_values(x):\n",
    "    if x == \"random\":\n",
    "        return 1\n",
    "    elif x == \"relevance sort\":\n",
    "        return 0\n",
    "    elif x == \"test list\":\n",
    "        return 0\n",
    "    elif x == \"supplemental coding\":\n",
    "        return 0\n",
    "    else:\n",
    "        return \"NaN\"\n",
    "\n",
    "df['random_sample']=df['sample_screen'].apply(map_values)\n",
    "\n",
    "df = (df\n",
    "      .sort_values('id')\n",
    "      .sample(frac=1, random_state=1)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df['text'] = df['title'] + \". \" + df['abstract'] + \" \" + \"Keywords: \" + df[\"keywords\"]\n",
    "df['text'] = df.apply(lambda row: (row['title'] + \". \" + row['abstract']) if pd.isna(row['text']) else row['text'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b33ddad-1b35-4568-8623-376e83c954ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oro_branch.Mitigation', 'oro_branch.Nature', 'oro_branch.Societal']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [0, 0, 1]\n",
       "1    [1, 0, 0]\n",
       "2    [1, 0, 0]\n",
       "3    [0, 1, 0]\n",
       "4    [0, 0, 1]\n",
       "Name: labels, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Format target columns as labels for the model\n",
    "targets = [x for x in df.columns if \"oro_branch\" in x] #Only need to change here, \"data_type\" for another variable\n",
    "print(targets)\n",
    "\n",
    "df['labels'] = list(df[targets].values)\n",
    "df['labels'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed3e9b3-83c1-4a45-90f8-05908a9b5c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████| 529/529 [00:02<00:00, 199.25 examples/s]\n",
      "Map: 100%|████████████████████████████| 427/427 [00:02<00:00, 204.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Convert pandas data frame to Dataset\n",
    "## separate into training (non-randomly sampled) and testing (randomly sampled)\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "train_datasets = Dataset.from_pandas(df.loc[df['random_sample'] == 0, ['text','labels','random_sample']])\n",
    "eval_datasets = Dataset.from_pandas(df.loc[df['random_sample'] == 1, ['text','labels','random_sample']])\n",
    "\n",
    "train_tokenized = train_datasets.map(tokenize_function, batched=True)\n",
    "eval_tokenized = eval_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e68f61b-bef5-4244-bb5d-afc9febaa016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 15:40:02.979120: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 2167820 bytes.\n",
      "2024-03-12 15:40:02.979149: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 2166784 at 0x302000a00\n",
      "2024-03-12 15:40:02.981729: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 4334604 bytes.\n",
      "2024-03-12 15:40:02.981748: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 2166784 at 0x302211a00\n",
      "2024-03-12 15:40:02.983327: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 4347300 bytes.\n",
      "2024-03-12 15:40:02.983343: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 12696 at 0x302422a00\n",
      "2024-03-12 15:40:02.994264: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 4347308 bytes.\n",
      "2024-03-12 15:40:02.994285: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 8 at 0x302425c00\n",
      "2024-03-12 15:40:02.994447: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 4347316 bytes.\n",
      "2024-03-12 15:40:02.994457: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 8 at 0x302425e00\n",
      "2024-03-12 15:40:02.999178: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 4347324 bytes.\n",
      "2024-03-12 15:40:02.999196: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 8 at 0x302426000\n",
      "2024-03-12 15:40:02.999925: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 4347325 bytes.\n",
      "2024-03-12 15:40:02.999938: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 1 at 0x302426200\n",
      "2024-03-12 15:40:03.005319: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 6096317 bytes.\n",
      "2024-03-12 15:40:03.005337: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 1748992 at 0x302426400\n",
      "2024-03-12 15:40:03.006766: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 7845309 bytes.\n",
      "2024-03-12 15:40:03.006784: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 1748992 at 0x3025d1400\n",
      "2024-03-12 15:40:03.008166: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 7855557 bytes.\n",
      "2024-03-12 15:40:03.008183: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 10248 at 0x30277c400\n",
      "2024-03-12 15:40:03.010457: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:306] New Peak memory usage of 7855565 bytes.\n",
      "2024-03-12 15:40:03.010474: I tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:315] gpu_async_0 Allocated 8 at 0x30277ee00\n"
     ]
    }
   ],
   "source": [
    "# Convert Dataset to big tensors and use the tf.data.Dataset.from_tensor_slices method\n",
    "full_train_dataset = train_tokenized\n",
    "full_eval_dataset = eval_tokenized\n",
    "\n",
    "tf_train_dataset = full_train_dataset.remove_columns([\"text\"]).with_format(\"tensorflow\")\n",
    "train_features = {x: tf_train_dataset[x] for x in tokenizer.model_input_names}\n",
    "train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_train_dataset['labels']))\n",
    "train_tf_dataset = train_tf_dataset.shuffle(len(tf_train_dataset)).batch(2) ## reduce batch size\n",
    "\n",
    "tf_eval_dataset = full_eval_dataset.remove_columns([\"text\"]).with_format(\"tensorflow\")\n",
    "eval_features = {x: tf_eval_dataset[x] for x in tokenizer.model_input_names}\n",
    "eval_tf_dataset = tf.data.Dataset.from_tensor_slices((eval_features, tf_eval_dataset['labels']))\n",
    "eval_tf_dataset = eval_tf_dataset.shuffle(len(tf_eval_dataset)).batch(2) ## reduce batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90c3c1e-9cb2-4287-86ef-4480e8f46466",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TFDistilBertForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# With this, the model can be compiled and trained \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# define model using best parameters gotten from model selection\u001b[39;00m\n\u001b[1;32m      4\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;66;03m# three oro branch labels\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFDistilBertForSequenceClassification\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m                                                               num_labels\u001b[38;5;241m=\u001b[39mnum_labels,\n\u001b[1;32m      7\u001b[0m                                                               id2label\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMitigation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNatural\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSocietal\u001b[39m\u001b[38;5;124m'\u001b[39m})  \n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tfa\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdamW(learning_rate\u001b[38;5;241m=\u001b[39mbest_model_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], weight_decay\u001b[38;5;241m=\u001b[39mbest_model_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TFDistilBertForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "# With this, the model can be compiled and trained \n",
    "\n",
    "# define model using best parameters gotten from model selection\n",
    "num_labels = 3 # three oro branch labels\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', \n",
    "                                                              num_labels=num_labels,\n",
    "                                                              id2label={0: 'Mitigation', 1: 'Natural', 2:'Societal'})  \n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=best_model_params['learning_rate'], weight_decay=best_model_params['weight_decay'])\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "# Fit model using training and evaluation datasets\n",
    "model.fit(train_tf_dataset, validation_data=eval_tf_dataset, epochs=best_model_params['num_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea96b6-2523-47dc-bd47-fd51de90bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.push_to_hub(\"distilbert_ORO_Branch\", use_auth_token = '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')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilBert_modelCard_env",
   "language": "python",
   "name": "distilbert_modelcard_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
